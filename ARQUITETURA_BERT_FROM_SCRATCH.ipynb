{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "mount_file_id": "1qa6EWtLf_SAb6XupyVs3XyHSzX5CRuFu",
      "authorship_tag": "ABX9TyOPcO/gVc3V5X8KZUg2cFil",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rhaymisonbetini/bert-model-from-scratch/blob/main/ARQUITETURA_BERT_FROM_SCRATCH.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "**BERT MODEL FROM SCRATCH**"
      ],
      "metadata": {
        "id": "MJR5Viq07S-D"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Q9SLEWoA7GMo"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "random.seed(10)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import math\n",
        "import torch\n",
        "import numpy as np\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from random import *"
      ],
      "metadata": {
        "id": "FGyofmpS7Zrp"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text = open('frases.txt','r').read()"
      ],
      "metadata": {
        "id": "V27sRkD173Ab"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sentences = re.sub(\"['.,!?\\\\n-]\",' ', text.lower()).split('\\\\n')\n",
        "word_list = list(set(\"\".join(sentences).split()))\n",
        "word_dict = {'[PAD]':0, '[CLS]':1, '[SEP]':2,'[MASK]':3}\n",
        "\n",
        "for i, w in enumerate(word_list):\n",
        "  word_dict[w] = i+4\n",
        "\n",
        "number_dict = {i:w for i, w in enumerate(word_dict)} # colocando os indices como chave e as palavras como valor no dicionario\n",
        "vocab_size = len(word_dict)\n",
        "token_list = list()\n",
        "\n",
        "for sentence in sentences:\n",
        "  arr = [word_dict[s] for s in sentence.split()]\n",
        "  token_list.append(arr)"
      ],
      "metadata": {
        "id": "v-v3C0uD8gRx"
      },
      "execution_count": 151,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#hiperparametros\n",
        "batch_size =6\n",
        "n_segments = 2\n",
        "dropout = 0.2\n",
        "\n",
        "#comprimento maximo\n",
        "maxlen = 100\n",
        "\n",
        "max_pred = 7 #numero de palavras a serem preditas\n",
        "\n",
        "n_layers = 6 #numero de camadas\n",
        "\n",
        "n_heads = 12 #numero de cabeças de mult head attention\n",
        "\n",
        "d_model = 768 #tamanho do embedding\n",
        "\n",
        "d_ff = d_model * 4 #tamanho do feed forward\n",
        "\n",
        "d_k = 64 # Dimensao de K(=Q)V\n",
        "\n",
        "d_v = 64 # Dimensao de K(=Q)V\n",
        "\n",
        "NUM_EPOCHS = 50 #numero de epocas"
      ],
      "metadata": {
        "id": "oycuRv_HEIWZ"
      },
      "execution_count": 154,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "CRIANDO **BATCHES**"
      ],
      "metadata": {
        "id": "eUYrdTOqHsVZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Função para criar os batches de dados\n",
        "def make_batch():\n",
        "\n",
        "    batch = []\n",
        "\n",
        "    positive = negative = 0\n",
        "\n",
        "    while positive != batch_size/2 or negative != batch_size/2:\n",
        "\n",
        "        tokens_a_index, tokens_b_index = randrange(len(sentences)), randrange(len(sentences))\n",
        "\n",
        "        tokens_a, tokens_b = token_list[tokens_a_index], token_list[tokens_b_index]\n",
        "\n",
        "        input_ids = [word_dict['[CLS]']] + tokens_a + [word_dict['[SEP]']] + tokens_b + [word_dict['[SEP]']]\n",
        "\n",
        "        segment_ids = [0] * (1 + len(tokens_a) + 1) + [1] * (len(tokens_b) + 1)\n",
        "\n",
        "        # MASK LM (MLM) de 15 % dos tokens em uma sentença\n",
        "        n_pred =  min(max_pred, max(1, int(round(len(input_ids) * 0.15))))\n",
        "\n",
        "        cand_maked_pos = [i for i, token in enumerate(input_ids)\n",
        "                          if token != word_dict['[CLS]'] and token != word_dict['[SEP]']]\n",
        "\n",
        "        shuffle(cand_maked_pos)\n",
        "\n",
        "        masked_tokens, masked_pos = [], []\n",
        "\n",
        "        for pos in cand_maked_pos[:n_pred]:\n",
        "\n",
        "            masked_pos.append(pos)\n",
        "\n",
        "            masked_tokens.append(input_ids[pos])\n",
        "\n",
        "            if random() < 0.8:\n",
        "                input_ids[pos] = word_dict['[MASK]']\n",
        "            elif random() < 0.5:\n",
        "                index = randint(0, vocab_size - 1)\n",
        "                input_ids[pos] = word_dict[number_dict[index]]\n",
        "\n",
        "        # Zero Paddings\n",
        "        n_pad = maxlen - len(input_ids)\n",
        "        input_ids.extend([0] * n_pad)\n",
        "        segment_ids.extend([0] * n_pad)\n",
        "\n",
        "        # Zero Padding (100% - 15%) tokens\n",
        "        if max_pred > n_pred:\n",
        "            n_pad = max_pred - n_pred\n",
        "            masked_tokens.extend([0] * n_pad)\n",
        "            masked_pos.extend([0] * n_pad)\n",
        "\n",
        "        if tokens_a_index + 1 == tokens_b_index and positive < batch_size / 2:\n",
        "\n",
        "            # IsNext\n",
        "            batch.append([input_ids, segment_ids, masked_tokens, masked_pos, True])\n",
        "            positive += 1\n",
        "        elif tokens_a_index + 1 != tokens_b_index and negative < batch_size / 2:\n",
        "\n",
        "            # NotNext\n",
        "            batch.append([input_ids, segment_ids, masked_tokens, masked_pos, False])\n",
        "            negative += 1\n",
        "\n",
        "    return batch"
      ],
      "metadata": {
        "id": "Jtp0Zy1THu9Z"
      },
      "execution_count": 155,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**ATTENTION MASK**"
      ],
      "metadata": {
        "id": "jlQT2G7ZJoJA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Função para o padding\n",
        "def get_attn_pad_masked(seq_q, seq_k):\n",
        "\n",
        "    batch_size, len_q = seq_q.size()\n",
        "\n",
        "    batch_size, len_k = seq_k.size()\n",
        "\n",
        "    pad_attn_masked = seq_k.data.eq(0).unsqueeze(1)\n",
        "\n",
        "    return pad_attn_masked.expand(batch_size, len_q, len_k)"
      ],
      "metadata": {
        "id": "1yAiMXM9JrUv"
      },
      "execution_count": 156,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch = make_batch()"
      ],
      "metadata": {
        "id": "omJAdienKE_B"
      },
      "execution_count": 157,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_ids, segment_ids, masked_tokens, masked_pos, isNext = map(torch.LongTensor, zip(*batch))"
      ],
      "metadata": {
        "id": "2i1XyntIKH8x"
      },
      "execution_count": 159,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "get_attn_pad_masked(input_ids, input_ids)[0][0], input_ids[0]"
      ],
      "metadata": {
        "id": "F4mWNGv3KbMd"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}